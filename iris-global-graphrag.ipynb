{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b2be3ef7-9cf5-4568-9304-136c294100d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in /opt/anaconda3/lib/python3.13/site-packages (2.2.0)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain_experimental in /opt/anaconda3/lib/python3.13/site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain_openai in /opt/anaconda3/lib/python3.13/site-packages (0.3.33)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.13/site-packages (0.11.0)\n",
      "Requirement already satisfied: intersystems-irispython in /opt/anaconda3/lib/python3.13/site-packages (5.2.1)\n",
      "Requirement already satisfied: sqlalchemy-iris in /opt/anaconda3/lib/python3.13/site-packages (0.18.0)\n",
      "Requirement already satisfied: sentence_transformers in /opt/anaconda3/lib/python3.13/site-packages (5.1.1)\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.46.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in /opt/anaconda3/lib/python3.13/site-packages (from arxiv) (6.0.12)\n",
      "Requirement already satisfied: requests~=2.32.0 in /opt/anaconda3/lib/python3.13/site-packages (from arxiv) (2.32.5)\n",
      "Requirement already satisfied: sgmllib3k in /opt/anaconda3/lib/python3.13/site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests~=2.32.0->arxiv) (2025.4.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /opt/anaconda3/lib/python3.13/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /opt/anaconda3/lib/python3.13/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/anaconda3/lib/python3.13/site-packages (from langchain) (0.4.30)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.13/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.13/site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain_experimental) (0.3.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.104.2 in /opt/anaconda3/lib/python3.13/site-packages (from langchain_openai) (1.108.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.13/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.13/site-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence_transformers) (4.56.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence_transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from sentence_transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from sentence_transformers) (0.35.1)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.13/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.17.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.10)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (5.5 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.117.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.13.1 (from gradio)\n",
      "  Downloading gradio_client-1.13.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (3.11.3)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (2.2.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.13.1-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from gradio) (0.13.2)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.37.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.13.1->gradio)\n",
      "  Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (1.5.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Downloading gradio-5.46.1-py3-none-any.whl (60.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.13.1-py3-none-any.whl (325 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading fastapi-0.117.1-py3-none-any.whl (95 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading Brotli-1.1.0-cp313-cp313-macosx_10_13_universal2.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.7/815.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.13.1-py3-none-macosx_11_0_arm64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.37.0-py3-none-any.whl (67 kB)\n",
      "Using cached ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, brotli, websockets, uvicorn, semantic-version, ruff, python-multipart, groovy, ffmpy, audioop-lts, aiofiles, starlette, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "\u001b[2K  Attempting uninstall: brotli\n",
      "\u001b[2K    Found existing installation: Brotli 1.0.9\n",
      "\u001b[2K    Uninstalling Brotli-1.0.9:\n",
      "\u001b[2K      Successfully uninstalled Brotli-1.0.9━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [brotli]\n",
      "\u001b[2K  Attempting uninstall: typer\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [ruff]\n",
      "\u001b[2K    Found existing installation: typer 0.9.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [ruff]\n",
      "\u001b[2K    Uninstalling typer-0.9.0:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [ruff]\n",
      "\u001b[2K      Successfully uninstalled typer-0.9.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [ruff]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [gradio]16/17\u001b[0m [gradio]client]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiofiles-24.1.0 audioop-lts-0.2.2 brotli-1.1.0 fastapi-0.117.1 ffmpy-0.6.1 gradio-5.46.1 gradio-client-1.13.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.13.1 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.48.0 typer-0.19.2 uvicorn-0.37.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install arxiv langchain langchain_experimental langchain_openai tiktoken intersystems-irispython sqlalchemy-iris sentence_transformers gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e526e5-745f-4f6d-ad3b-2151b4bcf2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc8254de-0915-457e-9014-62aa6245911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search any topic and replace the keyword below\n",
    "search_query = (\n",
    "    \"GraphRAG OR RAG OR 'knowledge graph' OR 'graph-based retrieval' OR 'graph reasoning' \"\n",
    "    \n",
    ")\n",
    "max_results = 50\n",
    "\n",
    "# Fetch papers from arXiv\n",
    "client = arxiv.Client()\n",
    "search = arxiv.Search(\n",
    "    query=search_query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance\n",
    ")\n",
    "\n",
    "docs = []\n",
    "for result in client.results(search):\n",
    "    docs.append(\n",
    "        {\"title\": result.title, \"abstract\": result.summary, \"url\": result.entry_id,  \"published\": result.published.date().isoformat(),\n",
    "         \"authors\": result.authors\n",
    "        }\n",
    "    )\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=2000, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.create_documents(\n",
    "    [doc[\"abstract\"]+\" \"+doc[\"title\"]+\"\"+str(doc[\"authors\"]) for doc in docs], metadatas=docs\n",
    ")\n",
    "\n",
    "docs_to_print = docs[:3]\n",
    "\n",
    "print(f\"Number of papers: {len(docs)}\")\n",
    "print(f\"Number of chunks: {len(doc_splits)}\") \n",
    "for i, doc in enumerate(docs_to_print, start=1):\n",
    "    authors_str = \", \".join([str(author) for author in doc['authors']]) \n",
    "    print(f\"Paper {i}:\")\n",
    "    print(f\"Title: {doc['title']}\")\n",
    "    print(f\"Abstract: {doc['abstract']}\")\n",
    "    print(f\"URL: {doc['url']}\")\n",
    "    print(f\"Published: {doc['published']}\")\n",
    "\n",
    "    print(f\"Authors: {authors_str}\")  \n",
    "    print(\"-\" * 50)  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6c030ac-2d8b-45b0-850f-d9c51f2e5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df = pd.DataFrame(docs)\n",
    "df['docid'] = range(len(df))\n",
    "\n",
    "df['authors'] = df['authors'].apply(lambda x: ast.literal_eval(str(x)) if isinstance(x, str) else x)\n",
    "\n",
    "# Remove special characters from author names and join authors with commas\n",
    "def clean_author_name(name):\n",
    "    if isinstance(name, str):\n",
    "        cleaned_name = re.sub(r'[^a-zA-Z\\s]', '', name)\n",
    "        return cleaned_name.strip()  # Ensure no leading/trailing spaces\n",
    "    return str(name)  \n",
    "\n",
    "df['authors'] = df['authors'].apply(lambda x: \", \".join([clean_author_name(str(author)) for author in x]))\n",
    "\n",
    "# print(df[['docid', 'title', 'authors']])\n",
    "\n",
    "df = df[['docid', 'title', 'abstract', 'url', 'published', 'authors']]\n",
    "\n",
    "output_csv_path = \"/Users/fji/Projects/iris-global-graphrag/data/papers.csv\"\n",
    "df.to_csv(output_csv_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a43fbbe-be43-459a-9664-8d460c88dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if \"OPENAI_API_KEY\" in os.environ:\n",
    "    os.environ.pop(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"): \n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ddac07e-51fb-40dc-870a-6a42c7870547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph documents: 50\n",
      "Nodes from 1st graph doc:[Node(id='When To Use Graphs In Rag: A Comprehensive Analysis For Graph Retrieval-Augmented Generation', type='Paper', properties={'title': 'When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation', 'abstract': 'Graph retrieval-augmented generation (GraphRAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) with external knowledge. It leverages graphs to model the hierarchical structure between specific concepts, enabling more coherent and effective knowledge retrieval for accurate reasoning. Despite its conceptual promise, recent studies report that GraphRAG frequently underperforms vanilla RAG on many real-world tasks. This raises a critical question: Is GraphRAG really effective, and in which scenarios do graph structures provide measurable benefits for RAG systems? To address this, we propose GraphRAG-Bench, a comprehensive benchmark designed to evaluate GraphRAG models on both hierarchical knowledge retrieval and deep contextual reasoning. GraphRAG-Bench features a comprehensive dataset with tasks of increasing difficulty, covering fact retrieval, complex reasoning, contextual summarization, and creative generation, and a systematic evaluation across the entire pipeline, from graph construction and knowledge retrieval to final generation. Leveraging this novel benchmark, we systematically investigate the conditions when GraphRAG surpasses traditional RAG and the underlying reasons for its success, offering guidelines for its practical application. All related resources and analyses are collected for the community at https://github.com/GraphRAG-Bench/GraphRAG-Benchmark.', 'url': 'https://github.com/GraphRAG-Bench/GraphRAG-Benchmark', 'author': 'Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, Shengyuan Chen, Zijin Hong, Xiao Huang, Jinsong Su'}), Node(id='Zhishang Xiang', type='Author', properties={}), Node(id='Chuanjie Wu', type='Author', properties={}), Node(id='Qinggang Zhang', type='Author', properties={}), Node(id='Shengyuan Chen', type='Author', properties={}), Node(id='Zijin Hong', type='Author', properties={}), Node(id='Xiao Huang', type='Author', properties={}), Node(id='Jinsong Su', type='Author', properties={}), Node(id='Graphrag', type='Topic', properties={}), Node(id='Rag', type='Topic', properties={}), Node(id='Graphrag-Bench', type='Topic', properties={}), Node(id='Large Language Models', type='Topic', properties={}), Node(id='External Knowledge', type='Topic', properties={}), Node(id='Graphs', type='Topic', properties={}), Node(id='Hierarchical Structure', type='Topic', properties={}), Node(id='Hierarchical Knowledge Retrieval', type='Topic', properties={}), Node(id='Deep Contextual Reasoning', type='Topic', properties={}), Node(id='Fact Retrieval', type='Topic', properties={}), Node(id='Complex Reasoning', type='Topic', properties={}), Node(id='Contextual Summarization', type='Topic', properties={}), Node(id='Creative Generation', type='Topic', properties={}), Node(id='Graph Construction', type='Topic', properties={}), Node(id='Knowledge Retrieval', type='Topic', properties={}), Node(id='Final Generation', type='Topic', properties={}), Node(id='Accurate Reasoning', type='Topic', properties={})]\n"
     ]
    }
   ],
   "source": [
    "graph_llm = ChatOpenAI(model_name=\"gpt-5\")\n",
    "graph_transformer = LLMGraphTransformer(\n",
    "    llm=graph_llm,\n",
    "    allowed_nodes=[\"Paper\", \"Author\", \"Topic\"],\n",
    "    node_properties=[\"title\", \"abstract\", \"url\", \"author\", \"published\"],\n",
    "    allowed_relationships=[ \"COVERS\", \"INCLUDES\",\"RELATED_TO\",\"AUTHORED\"],\n",
    ")\n",
    "\n",
    "graph_documents = graph_transformer.convert_to_graph_documents(doc_splits)\n",
    "\n",
    "print(f\"Graph documents: {len(graph_documents)}\")\n",
    "print(f\"Nodes from 1st graph doc:{graph_documents[0].nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "517e461f-a028-4ab9-ae20-af34b9cbda28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize_authored(graph_documents):\n",
    "    for doc in graph_documents:\n",
    "        for rel in getattr(doc, \"relationships\", []) or []:\n",
    "            if (getattr(rel, \"type\", \"\") or \"\").upper() != \"AUTHORED\":\n",
    "                continue\n",
    "            s, t = rel.source, rel.target\n",
    "            if getattr(s, \"type\", None) == \"Paper\" and getattr(t, \"type\", None) == \"Author\":\n",
    "                rel.source, rel.target = t, s  # flip to Author -> Paper\n",
    "    return graph_documents\n",
    "\n",
    "graph_documents = canonicalize_authored(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1a400f9-5b92-4232-89e8-2998a09edb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data_path = '/Users/fji/Projects/iris-global-graphrag/data/'\n",
    "filename = data_path + \"entities\" + \".csv\"\n",
    "\n",
    "# Open the file in write mode with 'newline=\"\"' to avoid extra blank lines\n",
    "with open(filename, \"w\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)  # Create a CSV writer object\n",
    "    writer.writerow([\"docid\", \"entityid\", \"type\"])  # Write the header row\n",
    "\n",
    "    # Loop through the graph_documents\n",
    "    for i, doc in enumerate(graph_documents):\n",
    "        if hasattr(doc, 'nodes') and isinstance(doc.nodes, list):  # Ensure 'nodes' is a list\n",
    "            for node in doc.nodes:\n",
    "                try:\n",
    "                    # Check if the 'id' and 'type' attributes exist in the node\n",
    "                    if hasattr(node, 'id') and hasattr(node, 'type'):\n",
    "                        # Write the data to the CSV file, split into three columns\n",
    "                        writer.writerow([i, node.id, node.type])\n",
    "                except UnicodeEncodeError:\n",
    "                    # Handle UnicodeEncodeError if there are problematic characters\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "893797fd-611d-45d2-afb2-65722898fb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/fji/Projects/iris-global-graphrag/data/'\n",
    "filename = data_path + \"relations\" + \".csv\"\n",
    "\n",
    "# Open the file in write mode with 'newline=\"\"' to avoid extra blank lines\n",
    "with open(filename, \"w\", newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)  # Create a CSV writer object\n",
    "    writer.writerow([\"docid\", \"source\", \"sourcetype\", \"target\", \"targettype\", \"type\"])  # Write the header row\n",
    "\n",
    "    # Loop through the graph_documents\n",
    "    for i, doc in enumerate(graph_documents):\n",
    "        # Check if the document has relationships\n",
    "        if hasattr(doc, 'relationships') and isinstance(doc.relationships, list):\n",
    "            # print(f\"Processing document {i}, relationships found.\")  # Debugging: Confirm relationships exist\n",
    "            for relation in doc.relationships:\n",
    "                try:\n",
    "                    # Extract the relevant data from the relationship\n",
    "                    source = relation.source\n",
    "                    target = relation.target\n",
    "\n",
    "                    # Check if the necessary attributes are present\n",
    "                    if hasattr(source, 'id') and hasattr(source, 'type') and hasattr(target, 'id') and hasattr(target, 'type'):\n",
    "                        # Write the data to the CSV file\n",
    "                        writer.writerow([i, source.id, source.type, target.id, target.type, relation.type])\n",
    "                    else:\n",
    "                        print(f\"  Missing attributes in relation: {relation}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error processing relation: {e}\")\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f22d70-94e7-48f8-afb7-6a20faa32806",
   "metadata": {},
   "source": [
    "## Setup IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d7d208bd-20d3-4498-8e3b-a5775d38a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "from sqlalchemy import create_engine,text\n",
    "\n",
    "args = {\n",
    "\t'hostname':'localhost', \n",
    "\t'port': 1972,\n",
    "\t'namespace':'USER', \n",
    "\t'username':'_SYSTEM', \n",
    "\t'password':'SYS',\n",
    "    'logfile':'log.txt'\n",
    "    \n",
    "}\n",
    "conn = iris.connect(**args)\n",
    "\n",
    "url = \"iris://_SYSTEM:SYS@localhost:1972/USER\"\n",
    "engine = create_engine(url)\n",
    "\n",
    "irispy = iris.createIRIS(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f93a63b9-0ef2-4802-9eec-614984457ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# irispy.kill(\"GraphRelations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "39c93846-a702-4452-993d-094a0cd6a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/fji/Projects/iris-global-graphrag/data/papers.csv\", newline='',encoding='utf-8-sig') as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "                for row in reader:\n",
    "                    docid = row['docid']\n",
    "                    title = row['title']\n",
    "                    abstract = row['abstract']\n",
    "                    url = row['url']\n",
    "                    published = row['published']\n",
    "                    authors = row['authors']\n",
    "                    irispy.set(title,    \"GraphContent\", docid, \"title\")\n",
    "                    irispy.set(abstract, \"GraphContent\", docid, \"abstract\")\n",
    "                    irispy.set(url,      \"GraphContent\", docid, \"url\")\n",
    "                    irispy.set(published,      \"GraphContent\", docid, \"published\")\n",
    "\n",
    "                    irispy.set(authors,  \"GraphContent\", docid, \"authors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1253d432-8922-4f83-8539-1b47fe2ccc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/fji/Projects/iris-global-graphrag/data/relations.csv\", newline='') as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "                for row in reader:\n",
    "                    docid = row ['docid']\n",
    "                    source = row['source']\n",
    "                    source_type = row['sourcetype']\n",
    "                    target = row['target']\n",
    "                    target_type = row['targettype']\n",
    "                    relation = row['type']\n",
    "         \n",
    "                    irispy.set(source_type, \"GraphRelations\",docid, \"Node\", source)\n",
    "                    irispy.set(target_type, \"GraphRelations\",docid, \"Node\", target)\n",
    "                    irispy.set(relation, \"GraphRelations\",docid, \"Edge\", source, target)\n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "28613d0e-5160-4bde-9ac2-1d7e59ef86bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When to use Graphs in RAG: A Comprehensive Ana...</td>\n",
       "      <td>Graph retrieval-augmented generation (GraphRAG...</td>\n",
       "      <td>http://arxiv.org/abs/2506.05690v1</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Benchmarking Vector, Graph and Hybrid Retrieva...</td>\n",
       "      <td>Generative AI (GenAI) is expected to play a pi...</td>\n",
       "      <td>http://arxiv.org/abs/2507.03608v2</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Sye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Graph-R1: Towards Agentic GraphRAG Framework v...</td>\n",
       "      <td>Retrieval-Augmented Generation (RAG) mitigates...</td>\n",
       "      <td>http://arxiv.org/abs/2507.21892v1</td>\n",
       "      <td>2025-07-29</td>\n",
       "      <td>Haoran Luo, Haihong E, Guanting Chen, Qika Lin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid                                              title  \\\n",
       "0      0  When to use Graphs in RAG: A Comprehensive Ana...   \n",
       "1      1  Benchmarking Vector, Graph and Hybrid Retrieva...   \n",
       "2      2  Graph-R1: Towards Agentic GraphRAG Framework v...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Graph retrieval-augmented generation (GraphRAG...   \n",
       "1  Generative AI (GenAI) is expected to play a pi...   \n",
       "2  Retrieval-Augmented Generation (RAG) mitigates...   \n",
       "\n",
       "                                 url   published  \\\n",
       "0  http://arxiv.org/abs/2506.05690v1  2025-06-06   \n",
       "1  http://arxiv.org/abs/2507.03608v2  2025-07-04   \n",
       "2  http://arxiv.org/abs/2507.21892v1  2025-07-29   \n",
       "\n",
       "                                             authors  \n",
       "0  Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, S...  \n",
       "1  Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Sye...  \n",
       "2  Haoran Luo, Haihong E, Guanting Chen, Qika Lin...  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"/Users/fji/Projects/iris-global-graphrag/data/papers.csv\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bedd308d-c820-4a06-92fa-f30684517c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>authors</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When to use Graphs in RAG: A Comprehensive Ana...</td>\n",
       "      <td>Graph retrieval-augmented generation (GraphRAG...</td>\n",
       "      <td>http://arxiv.org/abs/2506.05690v1</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, S...</td>\n",
       "      <td>docid: 0 | title: When to use Graphs in RAG: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Benchmarking Vector, Graph and Hybrid Retrieva...</td>\n",
       "      <td>Generative AI (GenAI) is expected to play a pi...</td>\n",
       "      <td>http://arxiv.org/abs/2507.03608v2</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Sye...</td>\n",
       "      <td>docid: 1 | title: Benchmarking Vector, Graph a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Graph-R1: Towards Agentic GraphRAG Framework v...</td>\n",
       "      <td>Retrieval-Augmented Generation (RAG) mitigates...</td>\n",
       "      <td>http://arxiv.org/abs/2507.21892v1</td>\n",
       "      <td>2025-07-29</td>\n",
       "      <td>Haoran Luo, Haihong E, Guanting Chen, Qika Lin...</td>\n",
       "      <td>docid: 2 | title: Graph-R1: Towards Agentic Gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid                                              title  \\\n",
       "0      0  When to use Graphs in RAG: A Comprehensive Ana...   \n",
       "1      1  Benchmarking Vector, Graph and Hybrid Retrieva...   \n",
       "2      2  Graph-R1: Towards Agentic GraphRAG Framework v...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Graph retrieval-augmented generation (GraphRAG...   \n",
       "1  Generative AI (GenAI) is expected to play a pi...   \n",
       "2  Retrieval-Augmented Generation (RAG) mitigates...   \n",
       "\n",
       "                                 url   published  \\\n",
       "0  http://arxiv.org/abs/2506.05690v1  2025-06-06   \n",
       "1  http://arxiv.org/abs/2507.03608v2  2025-07-04   \n",
       "2  http://arxiv.org/abs/2507.21892v1  2025-07-29   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, S...   \n",
       "1  Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Sye...   \n",
       "2  Haoran Luo, Haihong E, Guanting Chen, Qika Lin...   \n",
       "\n",
       "                                            combined  \n",
       "0  docid: 0 | title: When to use Graphs in RAG: A...  \n",
       "1  docid: 1 | title: Benchmarking Vector, Graph a...  \n",
       "2  docid: 2 | title: Graph-R1: Towards Agentic Gr...  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"combined\"] = df.apply(\n",
    "    lambda r: f\"docid: {r['docid']} | title: {r['title']} | abstract: {r['abstract']} | \"\n",
    "              f\"url: {r['url']} | published: {r['published']} | authors: {r['authors']}\",\n",
    "    axis=1\n",
    ")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "500e140f-4852-496a-944c-4cd5489b66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/fji/Projects/iris-global-graphrag/data/papers_combined.csv\", \n",
    "          index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d9ab3e02-176b-4f07-8828-9ce21b6da758",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():# Load \n",
    "        sql = f\"\"\"\n",
    "                drop TABLE paper_content \n",
    "                \"\"\"\n",
    "        result = conn.execute(text(sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a862dc5e-950e-4391-a45c-531088c4cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():# Load \n",
    "        sql = f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS paper_content (\n",
    "                    docid VARCHAR(255),\n",
    "                    title VARCHAR(255),\n",
    "                    abstract VARCHAR(2000),\n",
    "                    url VARCHAR(255),\n",
    "                    published VARCHAR(255),\n",
    "                    authors VARCHAR(255),\n",
    "                    combined VARCHAR(10000),\n",
    "                    paper_vector VECTOR(FLOAT, 384)\n",
    "\n",
    "                )\n",
    "                \"\"\"\n",
    "        result = conn.execute(text(sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2d39ed33-e53a-4aa5-9c35-1cf7d763bfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>published</th>\n",
       "      <th>authors</th>\n",
       "      <th>combined</th>\n",
       "      <th>paper_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When to use Graphs in RAG: A Comprehensive Ana...</td>\n",
       "      <td>Graph retrieval-augmented generation (GraphRAG...</td>\n",
       "      <td>http://arxiv.org/abs/2506.05690v1</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, S...</td>\n",
       "      <td>docid: 0 | title: When to use Graphs in RAG: A...</td>\n",
       "      <td>[-0.05978081375360489, 0.006263501010835171, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Benchmarking Vector, Graph and Hybrid Retrieva...</td>\n",
       "      <td>Generative AI (GenAI) is expected to play a pi...</td>\n",
       "      <td>http://arxiv.org/abs/2507.03608v2</td>\n",
       "      <td>2025-07-04</td>\n",
       "      <td>Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Sye...</td>\n",
       "      <td>docid: 1 | title: Benchmarking Vector, Graph a...</td>\n",
       "      <td>[-0.08074361085891724, -0.01096606906503439, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Graph-R1: Towards Agentic GraphRAG Framework v...</td>\n",
       "      <td>Retrieval-Augmented Generation (RAG) mitigates...</td>\n",
       "      <td>http://arxiv.org/abs/2507.21892v1</td>\n",
       "      <td>2025-07-29</td>\n",
       "      <td>Haoran Luo, Haihong E, Guanting Chen, Qika Lin...</td>\n",
       "      <td>docid: 2 | title: Graph-R1: Towards Agentic Gr...</td>\n",
       "      <td>[-0.04313172027468681, 0.05216117948293686, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RAG vs. GraphRAG: A Systematic Evaluation and ...</td>\n",
       "      <td>Retrieval-Augmented Generation (RAG) enhances ...</td>\n",
       "      <td>http://arxiv.org/abs/2502.11371v1</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>Haoyu Han, Harry Shomer, Yu Wang, Yongjia Lei,...</td>\n",
       "      <td>docid: 3 | title: RAG vs. GraphRAG: A Systemat...</td>\n",
       "      <td>[-0.06944005936384201, 0.07515047490596771, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Empowering GraphRAG with Knowledge Filtering a...</td>\n",
       "      <td>In recent years, large language models (LLMs) ...</td>\n",
       "      <td>http://arxiv.org/abs/2503.13804v1</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>Kai Guo, Harry Shomer, Shenglai Zeng, Haoyu Ha...</td>\n",
       "      <td>docid: 4 | title: Empowering GraphRAG with Kno...</td>\n",
       "      <td>[-0.052577532827854156, 0.01960759237408638, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid                                              title  \\\n",
       "0      0  When to use Graphs in RAG: A Comprehensive Ana...   \n",
       "1      1  Benchmarking Vector, Graph and Hybrid Retrieva...   \n",
       "2      2  Graph-R1: Towards Agentic GraphRAG Framework v...   \n",
       "3      3  RAG vs. GraphRAG: A Systematic Evaluation and ...   \n",
       "4      4  Empowering GraphRAG with Knowledge Filtering a...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Graph retrieval-augmented generation (GraphRAG...   \n",
       "1  Generative AI (GenAI) is expected to play a pi...   \n",
       "2  Retrieval-Augmented Generation (RAG) mitigates...   \n",
       "3  Retrieval-Augmented Generation (RAG) enhances ...   \n",
       "4  In recent years, large language models (LLMs) ...   \n",
       "\n",
       "                                 url   published  \\\n",
       "0  http://arxiv.org/abs/2506.05690v1  2025-06-06   \n",
       "1  http://arxiv.org/abs/2507.03608v2  2025-07-04   \n",
       "2  http://arxiv.org/abs/2507.21892v1  2025-07-29   \n",
       "3  http://arxiv.org/abs/2502.11371v1  2025-02-17   \n",
       "4  http://arxiv.org/abs/2503.13804v1  2025-03-18   \n",
       "\n",
       "                                             authors  \\\n",
       "0  Zhishang Xiang, Chuanjie Wu, Qinggang Zhang, S...   \n",
       "1  Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Sye...   \n",
       "2  Haoran Luo, Haihong E, Guanting Chen, Qika Lin...   \n",
       "3  Haoyu Han, Harry Shomer, Yu Wang, Yongjia Lei,...   \n",
       "4  Kai Guo, Harry Shomer, Shenglai Zeng, Haoyu Ha...   \n",
       "\n",
       "                                            combined  \\\n",
       "0  docid: 0 | title: When to use Graphs in RAG: A...   \n",
       "1  docid: 1 | title: Benchmarking Vector, Graph a...   \n",
       "2  docid: 2 | title: Graph-R1: Towards Agentic Gr...   \n",
       "3  docid: 3 | title: RAG vs. GraphRAG: A Systemat...   \n",
       "4  docid: 4 | title: Empowering GraphRAG with Kno...   \n",
       "\n",
       "                                        paper_vector  \n",
       "0  [-0.05978081375360489, 0.006263501010835171, 0...  \n",
       "1  [-0.08074361085891724, -0.01096606906503439, -...  \n",
       "2  [-0.04313172027468681, 0.05216117948293686, -0...  \n",
       "3  [-0.06944005936384201, 0.07515047490596771, 0....  \n",
       "4  [-0.052577532827854156, 0.01960759237408638, -...  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "emb_model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "embeddings = emb_model.encode(df['combined'].tolist(), normalize_embeddings=True)\n",
    "\n",
    "# Add the embeddings to the DataFrame\n",
    "df['paper_vector'] = embeddings.tolist()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5cc27e3e-764a-4da3-b452-b50de2a33450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():\n",
    "        for index, row in df.iterrows():\n",
    "            sql = text(\"\"\"\n",
    "                INSERT INTO paper_content \n",
    "                (docid, title, abstract, url, published, authors, combined, paper_vector) \n",
    "                VALUES (:docid, :title, :abstract, :url, :published, :authors, :combined, TO_VECTOR(:paper_vector))\n",
    "            \"\"\")\n",
    "            conn.execute(sql, {\n",
    "                'docid': row['docid'], \n",
    "                'title': row['title'],\n",
    "                'abstract': row['abstract'],\n",
    "                'url': row['url'],\n",
    "                'published': row['published'], \n",
    "                'authors': row['authors'], \n",
    "                'combined': row['combined'],\n",
    "                'paper_vector': str(row['paper_vector'])\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6acd42f2-673b-4ebe-9af3-08851831c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    with conn.begin():# Load \n",
    "        sql = f\"\"\"\n",
    "               CREATE INDEX HNSWIndex ON TABLE paper_content (paper_vector) AS HNSW(Distance='DotProduct')\n",
    "                \"\"\"\n",
    "        result = conn.execute(text(sql))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "14eedb86-f9c1-4284-930e-c652e6469653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "def search_papers(engine, search_vector, top_k):\n",
    "    sql = text(f\"\"\"\n",
    "        SELECT TOP {top_k} combined\n",
    "        FROM paper_content\n",
    "        ORDER BY VECTOR_DOT_PRODUCT(paper_vector, TO_VECTOR(:search_vector)) DESC\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        with conn.begin():\n",
    "            rows = conn.execute(sql, {\"search_vector\": str(search_vector)}).fetchall()\n",
    "\n",
    "    # Flatten 1-element tuples into a list of strings\n",
    "    flattened = [r[0] for r in rows]\n",
    "    return flattened\n",
    "\n",
    "# test\n",
    "\n",
    "# search_query = \"who has written the most paper\"\n",
    "# search_vector = emb_model.encode(search_query, normalize_embeddings=True).tolist() # Convert search phrase into a vector\n",
    "# results = search_papers(engine,search_vector,5)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e64061e-10e5-48d1-a370-95d031d16ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "client = OpenAI()\n",
    "\n",
    "def send_to_llm(model, messages,**kwargs):\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        **kwargs\n",
    "\n",
    "\n",
    "    )\n",
    "    return completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60097247-9af7-40f2-b71d-f5a11cbe3850",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4f0f3742-b4c7-486d-a4c5-42c231b146f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer_rag(batch, query, cutoff=True):\n",
    " \n",
    "\n",
    "    prompt_text = \"\"\"You are an expert assistant for graph-based academic search. \n",
    "    You are given a graph context of academic papers including authors, abstracts, published date.\n",
    "    Use the following pieces of retrieved context from the database to answer the question.\n",
    "    \"\"\" + ((\"Use three sentences maximum and keep the answer concise.\") if cutoff else \" \") + \"\"\"\n",
    "    Question: {question}  \n",
    "    Context: {context}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = prompt_text.format(**{\"question\": query, \"context\": batch})\n",
    " \n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    completion = send_to_llm(model, messages)\n",
    "    response = completion.choices[0].message.content\n",
    " \n",
    "    answer_lines = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "\n",
    "\n",
    "\n",
    "    return answer_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6ed2c24-bcbf-4b29-8e4f-91a59496bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_rag(query: str, engine, emb_model, top_k: int = 5):\n",
    "\n",
    "    search_vector = emb_model.encode(query, normalize_embeddings=True).tolist()\n",
    "\n",
    "    results = search_papers(engine, search_vector, top_k)\n",
    "\n",
    "    response = llm_answer_rag(results, query, True)\n",
    "    if isinstance(response, list):\n",
    "        response = \" \".join(response)\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09c3da43-3a17-4927-aab2-652bd3887301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphRAG is a framework that enhances retrieval-augmented generation (RAG) by leveraging the structural information of graphs to improve the accuracy and context of responses generated by large language models (LLMs). It addresses challenges such as knowledge gaps and hallucinations by integrating structured knowledge from external graphs. Recent studies propose various enhancements and modular frameworks to optimize GraphRAG's performance across different domains.\n"
     ]
    }
   ],
   "source": [
    "response = ask_question_rag(search_query, engine, emb_model, top_k=5)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeaf22a-947d-460a-a0ab-1e2bb0898fd8",
   "metadata": {},
   "source": [
    "## GraphRAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7641b5ab-0557-431d-a210-bedfe183fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_for_doc(doc_id: int, iris_handle, global_name=\"^GraphRelations\"):\n",
    "\n",
    "    nodes = []\n",
    "    for name, node_type in iris_handle.iterator(global_name, doc_id, \"Node\"):\n",
    "        nodes.append({\"name\": name, \"type\": node_type})\n",
    "\n",
    "\n",
    "    edges = []\n",
    "    for src, _ in iris_handle.iterator(global_name, doc_id, \"Edge\"):\n",
    "        for dst, rel in iris_handle.iterator(global_name, doc_id, \"Edge\", src):\n",
    "            edges.append({\"source\": src, \"target\": dst, \"relation\": rel})\n",
    "\n",
    "    return {\"doc_id\": doc_id, \"nodes\": nodes, \"edges\": edges}\n",
    "\n",
    "# # test\n",
    "# graph = get_graph_for_doc(0, irispy)\n",
    "\n",
    "# print(\"Doc ID:\", graph[\"doc_id\"])\n",
    "# print(\"\\nNodes:\")\n",
    "# for n in graph[\"nodes\"]:\n",
    "#     print(f\"  - {n['name']} ({n['type']})\")\n",
    "\n",
    "# print(\"\\nEdges:\")\n",
    "# for e in graph[\"edges\"]:\n",
    "#     print(f\"  - {e['source']} --[{e['relation']}]-> {e['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0a27c828-46f8-46d0-831b-6d043a30c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_papers_id(engine, search_vector,top_k):\n",
    "\n",
    "    sql = text(f\"\"\"\n",
    "         SELECT TOP {top_k} docid FROM paper_content ORDER BY VECTOR_DOT_PRODUCT(paper_vector, TO_VECTOR(:search_vector)) DESC\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        with conn.begin():\n",
    "            resultsID = conn.execute(sql, {\"search_vector\": str(search_vector)}).fetchall()\n",
    "    results = [row[0] for row in resultsID]\n",
    "    return results\n",
    "    \n",
    "\n",
    "# # # test\n",
    "# search_query = \"What is Knowledge graph\"\n",
    "# search_vector = emb_model.encode(search_query, normalize_embeddings=True).tolist() \n",
    "# results = search_papers_id(engine, search_vector,5)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ce643d2-d84d-4567-84d6-d82d709d5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graphs_for_docs(doc_ids, iris_handle, global_name=\"^GraphRelations\"):\n",
    "    graphs = []\n",
    "    for doc_id in doc_ids:\n",
    "        # ensure int (in case SQL returns strings)\n",
    "        gid = int(doc_id)\n",
    "        graphs.append(get_graph_for_doc(gid, iris_handle, global_name))\n",
    "    return graphs\n",
    "\n",
    " \n",
    "doc_ids = search_papers_id(engine, search_vector, top_k=5)\n",
    "# #test\n",
    "# print(\"doc_ids:\", doc_ids)\n",
    "\n",
    "graphs = get_graphs_for_docs(doc_ids, irispy)\n",
    "# #test\n",
    "# print(graphs[:1]) \n",
    "# print(json.dumps(graphs[:2], ensure_ascii=False, indent=2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1cb4200-f893-4aed-99b9-733ae2fdd78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_for_docs(doc_ids, irispy, global_name=\"^GraphContent\"):\n",
    "\n",
    "    results = []\n",
    "    fields = [\"title\", \"abstract\", \"authors\", \"published\", \"url\"]\n",
    "\n",
    "    for doc_id in doc_ids:\n",
    "        doc_data = {\"doc_id\": int(doc_id)}\n",
    "        for field in fields:\n",
    "            value = irispy.get(global_name, doc_id, field)\n",
    "            if value is not None:\n",
    "                doc_data[field] = str(value)\n",
    "        results.append(doc_data)\n",
    "\n",
    "    return results\n",
    "\n",
    "# #test\n",
    "# results = get_content_for_docs(doc_ids, irispy)\n",
    "# print(results[:10])\n",
    "# print(json.dumps(results, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e7630ed3-8452-4414-94a9-f8501225550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_answer_graphrag(batch, query, cutoff=True):\n",
    " \n",
    "\n",
    "    prompt_text = \"\"\"You are an expert assistant for graph-based academic search. \n",
    "    You are given a graph context of academic papers including authors, abstracts, published date.\n",
    "    Use the following pieces of retrieved context from a graph database to answer the question.\n",
    "    \"\"\" + ((\"Use three sentences maximum and keep the answer concise.\") if cutoff else \" \") + \"\"\"\n",
    "    Question: {question}  \n",
    "    Graph Context: {graph_context}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = prompt_text.format(**{\"question\": query, \"graph_context\": batch})\n",
    " \n",
    "    messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    completion = send_to_llm(model, messages)\n",
    "    response = completion.choices[0].message.content\n",
    " \n",
    "    answer_lines = [line.strip() for line in response.split('\\n') if line.strip()]\n",
    "\n",
    "\n",
    "\n",
    "    return answer_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e6f17ecb-9547-4490-9f45-3ef835bdd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_combined_results(query, engine, emb_model, irispy, top_k=5):\n",
    "    search_vector = emb_model.encode(query, normalize_embeddings=True).tolist()\n",
    "    doc_ids = search_papers_id(engine, search_vector, top_k=top_k)\n",
    "    return {\n",
    "        \"papers\": get_content_for_docs(doc_ids, irispy),\n",
    "        \"graphs\": get_graphs_for_docs(doc_ids, irispy)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ee802a1-1c28-4b4c-ab60-d3fbb7796ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_graphrag(query: str, engine, emb_model, irispy, top_k: int = 5):\n",
    "    # search_vector = emb_model.encode(query, normalize_embeddings=True).tolist()\n",
    "\n",
    "    # doc_ids = search_papers_id(engine, search_vector, top_k=top_k)\n",
    "\n",
    "    # results_graph = get_graphs_for_docs(doc_ids, irispy)\n",
    "    # results_paper = get_content_for_docs(doc_ids, irispy)\n",
    "\n",
    "    # combined_results = {\n",
    "    #     \"papers\": results_paper,\n",
    "    #     \"graphs\": results_graph\n",
    "    # }\n",
    "    combined_results = prepare_combined_results\n",
    "\n",
    "    response = llm_answer_graphrag(combined_results, query, True)\n",
    "    if isinstance(response, list):\n",
    "            response = \" \".join(response)\n",
    "    return response\n",
    "\n",
    "# #test\n",
    "# print(doc_ids)\n",
    "# results = json.dumps(combined_results, ensure_ascii=False, indent=2)\n",
    "# print(results[:10000])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a5cc93e2-3179-4952-9c0a-3dfc89cafccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphRAG is a framework that combines retrieval-augmented generation (RAG) with graph-structured data to enhance the accuracy and contextual relevance of responses generated by large language models (LLMs). It leverages the relational information in knowledge graphs to improve the precision of information retrieval and generation tasks. Recent studies have proposed modular frameworks and techniques to address challenges in implementing GraphRAG effectively across various domains.\n"
     ]
    }
   ],
   "source": [
    "response = ask_question_graphrag(\"what is graphrag\", engine, emb_model, irispy)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a9dda-55be-4115-a563-57e5152296db",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c564fb13-6a6c-4088-9c45-0907e15252de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_papers_by_author(\n",
    "    author: str,\n",
    "    iris_handle,\n",
    "    relations_global=\"^GraphRelations\",\n",
    "    content_global=\"^GraphContent\",\n",
    "    include_content=True,\n",
    "    case_insensitive=True,\n",
    "):\n",
    "    def _eq(a, b):\n",
    "        return a.lower() == b.lower() if case_insensitive else a == b\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # iterate all docIds at the top level\n",
    "    for doc_id, _ in iris_handle.iterator(relations_global):\n",
    "        # iterate edge sources for this doc\n",
    "        for src, _ in iris_handle.iterator(relations_global, doc_id, \"Edge\"):\n",
    "            if not _eq(str(src), author):\n",
    "                continue\n",
    "            # iterate destinations; filter on relation == \"AUTHORED\"\n",
    "            for dst, rel in iris_handle.iterator(relations_global, doc_id, \"Edge\", src):\n",
    "                if str(rel).upper() != \"AUTHORED\":\n",
    "                    continue\n",
    "\n",
    "                item = {\n",
    "                    \"doc_id\": int(doc_id),\n",
    "                    \"author\": str(src),\n",
    "                    \"title\": str(dst)\n",
    "                }\n",
    "\n",
    "                if include_content:\n",
    "                    # pull extra fields from ^GraphContent\n",
    "                    for f in (\"title\", \"abstract\", \"authors\", \"published\", \"url\"):\n",
    "                        val = iris_handle.get(content_global, doc_id, f)\n",
    "                        if val is not None:\n",
    "                            item[f] = str(val)\n",
    "\n",
    "                results.append(item)\n",
    "\n",
    "    return results\n",
    "#test\n",
    "# papers = get_papers_by_author(\"TEST Name\", irispy)\n",
    "\n",
    "# print(json.dumps(papers, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e2b5f845-d3b1-4a8c-8dc3-2bbe5a0cba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_papers_by_topic(\n",
    "    irispy,\n",
    "    topic,\n",
    "    relations_global=\"^GraphRelations\",\n",
    "    content_global=\"^GraphContent\",\n",
    "    edge_root=\"Edge\",\n",
    "    require_value=\"COVERS\",\n",
    "    case_insensitive=True,\n",
    "    include_content=True   # just add this\n",
    "\n",
    "):\n",
    "\n",
    "\n",
    "    def _eq(a, b):\n",
    "        return a.lower() == b.lower() if case_insensitive else a == b\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # iterate all doc_ids\n",
    "    for doc_id, _ in irispy.iterator(relations_global):\n",
    "        for paper, _ in irispy.iterator(relations_global, doc_id, edge_root):\n",
    "            for dst_topic, relation in irispy.iterator(relations_global, doc_id, edge_root, paper):\n",
    "                if not _eq(str(dst_topic), topic):\n",
    "                    continue\n",
    "                if require_value and str(relation).upper() != str(require_value).upper():\n",
    "                    continue\n",
    "\n",
    "                # start with relation info\n",
    "                item = {\n",
    "                    \"doc_id\": int(doc_id),\n",
    "                    \"paper\": str(paper),\n",
    "                    \"topic\": str(dst_topic),\n",
    "                    \"relation\": str(relation),\n",
    "                }\n",
    "\n",
    "                # add paper metadata if available\n",
    "                for f in (\"title\", \"abstract\", \"authors\", \"published\", \"url\"):\n",
    "                    v = irispy.get(content_global, doc_id, f)\n",
    "                    if v is not None:\n",
    "                        item[f] = str(v)\n",
    "\n",
    "                results.append(item)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# # ? it can only find exact match\n",
    "# #test\n",
    "# hits = get_papers_by_topic(irispy, \"Knowledge Graphs\")\n",
    "\n",
    "# print(json.dumps(hits, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ef24f16f-2dd2-47c1-80ff-c92e4284c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_authors_by_paper_count(\n",
    "    irispy,\n",
    "    limit: int = 10,\n",
    "    relations_global: str = \"^GraphRelations\",\n",
    "    content_global: str = \"^GraphContent\",\n",
    "    edge_root: str = \"Edge\",\n",
    "    authored_value: str = \"AUTHORED\",\n",
    "    case_insensitive: bool = True,\n",
    "    dedup: bool = True,\n",
    "):\n",
    "\n",
    "    counts = {}            # key -> {\"author\": display, \"count\": int, \"papers\": [ ... ]}\n",
    "    seen_pairs = {}        # key -> set of (doc_id, paper_node) to avoid double-counting\n",
    "\n",
    "    for doc_id, _ in irispy.iterator(relations_global):\n",
    "        for author, _ in irispy.iterator(relations_global, doc_id, edge_root):\n",
    "            for paper, rel in irispy.iterator(relations_global, doc_id, edge_root, author):\n",
    "                if str(rel).upper() != authored_value.upper():\n",
    "                    continue\n",
    "\n",
    "                key = (str(author).lower() if case_insensitive else str(author))\n",
    "\n",
    "                # de-dup per (doc_id, paper) for this author\n",
    "                if dedup:\n",
    "                    sp = seen_pairs.setdefault(key, set())\n",
    "                    pair = (int(doc_id), str(paper))\n",
    "                    if pair in sp:\n",
    "                        continue\n",
    "                    sp.add(pair)\n",
    "\n",
    "                entry = counts.setdefault(key, {\"author\": str(author), \"count\": 0, \"papers\": []})\n",
    "                entry[\"count\"] += 1\n",
    "\n",
    "                # paper details from ^GraphContent\n",
    "                paper_info = {\n",
    "                    \"doc_id\": int(doc_id),\n",
    "                    \"paper_node\": str(paper),  # name used in the Edge subscript\n",
    "                }\n",
    "                for f in (\"title\", \"abstract\", \"authors\", \"published\", \"url\"):\n",
    "                    v = irispy.get(content_global, doc_id, f)\n",
    "                    if v is not None:\n",
    "                        paper_info[f] = str(v)\n",
    "\n",
    "                entry[\"papers\"].append(paper_info)\n",
    "\n",
    "    # sort and trim\n",
    "    items = sorted(counts.values(), key=lambda x: (-x[\"count\"], x[\"author\"].lower()))\n",
    "    return items[:max(1, int(limit))]\n",
    "# #test\n",
    "# top = get_top_authors_by_paper_count(irispy, limit=5)\n",
    "# import json\n",
    "# print(json.dumps(top, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "257b4c49-60e0-4689-9882-1200c79b7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_top_authors_by_paper_count\",\n",
    "            \"description\": \"Return the top authors ranked by number of authored papers.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"limit\": {\"type\": \"integer\", \"default\": 5, \"minimum\": 1, \"maximum\": 100}\n",
    "                },\n",
    "                \"required\": []\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_papers_by_author\",\n",
    "            \"description\": \"Return papers authored by the specified author, optionally with metadata.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"author\": {\"type\": \"string\", \"description\": \"Author full name\"},\n",
    "                    \"include_content\": {\"type\": \"boolean\", \"default\": True}\n",
    "                },\n",
    "                \"required\": [\"author\"]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_papers_by_topic\",\n",
    "            \"description\": \"Return papers related to the specified topic, with relations and metadata.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"topic\": {\"type\": \"string\"},\n",
    "                    \"include_content\": {\"type\": \"boolean\", \"default\": True}\n",
    "                },\n",
    "                \"required\": [\"topic\"]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "# -------- routing instruction --------\n",
    "ROUTER_SYSTEM = (\n",
    "    \"You are a routing assistant for a graph-of-papers. \"\n",
    "    \"Choose and call the correct tool(s). Examples:\\n\"\n",
    "    \"- 'who has written the most paper' -> call get_top_authors_by_paper_count(limit=5)\\n\"\n",
    "    \"- 'what did Harry Shomer write' -> call get_papers_by_author(author='Harry Shomer')\\n\"\n",
    "    \"- 'papers about Knowledge Graphs' -> call get_papers_by_topic(topic='Knowledge Graphs')\\n\"\n",
    "    \"After tool results come back, summarize concisely.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "46d17268-6c4a-4b47-8586-c35030ba8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(user_query: str, irispy, limit_default: int = 5, debug: bool = True):\n",
    "    messages = [\n",
    "        # {\"role\": \"system\", \"content\": \"Route to the correct tool. Answer concisely after tools.\"},\n",
    "        {\"role\": \"system\", \"content\": ROUTER_SYSTEM},\n",
    "\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "    ]\n",
    "\n",
    "    def call_tools(name: str, args: dict):\n",
    "        if debug:\n",
    "            print(f\"[Agent] → {name}({args})\")\n",
    "        if name == \"get_top_authors_by_paper_count\":\n",
    "            return get_top_authors_by_paper_count(irispy, limit=int(args.get(\"limit\", limit_default)))\n",
    "        if name == \"get_papers_by_author\":\n",
    "            return get_papers_by_author(args[\"author\"], irispy, include_content=bool(args.get(\"include_content\", True)))\n",
    "        if name == \"get_papers_by_topic\":\n",
    "            return get_papers_by_topic(irispy, args[\"topic\"],  include_content=bool(args.get(\"include_content\", True)))\n",
    "        return {\"error\": f\"unknown tool {name}\"}\n",
    "\n",
    "    for step in range(3):\n",
    "        if debug: print(f\"[Agent] step {step+1}\")\n",
    "\n",
    "        # Ask model what to do\n",
    "        resp = send_to_llm(model, messages, tools=tools)\n",
    "\n",
    "        msg = resp.choices[0].message\n",
    "        tool_calls = msg.tool_calls or []\n",
    "\n",
    "        # IMPORTANT: append the assistant message with tool_calls BEFORE tool outputs\n",
    "        if tool_calls:\n",
    "            # convert tool_calls to plain dicts (SDK objects aren’t JSON serializable)\n",
    "            tc_dicts = [{\n",
    "                \"id\": tc.id,\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\"name\": tc.function.name, \"arguments\": tc.function.arguments}\n",
    "            } for tc in tool_calls]\n",
    "\n",
    "            messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": msg.content or \"\",\n",
    "                \"tool_calls\": tc_dicts\n",
    "            })\n",
    "\n",
    "            # Execute each tool and append the tool result\n",
    "            for tc in tool_calls:\n",
    "                fn_name = tc.function.name\n",
    "                fn_args = json.loads(tc.function.arguments or \"{}\")\n",
    "                result = call_tools(fn_name, fn_args)\n",
    "\n",
    "                if debug:\n",
    "                    preview = json.dumps(result, ensure_ascii=False)[:200]\n",
    "                    print(f\"[Agent] result: {preview}...\\n\")\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tc.id,\n",
    "                    \"name\": fn_name,\n",
    "                    \"content\": json.dumps(result, ensure_ascii=False)\n",
    "                })\n",
    "\n",
    "            # loop continues; model will now see the tool outputs and (usually) produce final answer\n",
    "            continue\n",
    "\n",
    "        # No tool calls → final answer\n",
    "        if debug: print(\"[Agent] ✓ Final answer\")\n",
    "        return msg.content\n",
    "\n",
    "    return \"Agent stopped: max steps reached.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d12d943-e457-4ee7-bee4-7956c3a4c1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] step 1\n",
      "[Agent] → get_top_authors_by_paper_count({'limit': 5})\n",
      "[Agent] result: [{\"author\": \"Xiao Huang\", \"count\": 5, \"papers\": [{\"doc_id\": 0, \"paper_node\": \"When To Use Graphs In Rag: A Comprehensive Analysis For Graph Retrieval-Augmented Generation\", \"title\": \"When to use Graph...\n",
      "\n",
      "[Agent] step 2\n",
      "[Agent] ✓ Final answer\n",
      "The author who has written the most papers is **Xiao Huang**, with a total of **5 papers**. Here are some of the notable papers authored by him:\n",
      "\n",
      "1. **[When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation](http://arxiv.org/abs/2506.05690v1)** - This paper discusses the effectiveness of Graph Retrieval-Augmented Generation (GraphRAG) and introduces a benchmark for evaluating its performance.\n",
      "   \n",
      "2. **[A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models](http://arxiv.org/abs/2501.13958v2)** - This survey analyzes the challenges and innovations in customizing large language models using GraphRAG.\n",
      "\n",
      "3. **[GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation](http://arxiv.org/abs/2506.02404v3)** - This paper presents a benchmark designed to rigorously evaluate GraphRAG models.\n",
      "\n",
      "Other authors with notable contributions include **Chuang Zhou**, **Haoyu Han**, **Harry Shomer**, and **Jiliang Tang**, each with 3 papers.\n"
     ]
    }
   ],
   "source": [
    "print(run_agent(\"who has written the most paper?\", irispy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3d6a1e3d-31eb-443f-985a-c8e7f06d99ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] step 1\n",
      "[Agent] → get_papers_by_author({'author': 'Xiao Huang'})\n",
      "[Agent] result: [{\"doc_id\": 0, \"author\": \"Xiao Huang\", \"title\": \"When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation\", \"abstract\": \"Graph retrieval-augmented generation (Graph...\n",
      "\n",
      "[Agent] step 2\n",
      "[Agent] ✓ Final answer\n",
      "Xiao Huang has authored several papers, including:\n",
      "\n",
      "1. **When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation**  \n",
      "   - **Abstract**: This paper discusses the effectiveness of Graph Retrieval-Augmented Generation (GraphRAG) in enhancing large language models (LLMs) with external knowledge, proposing a benchmark to evaluate its performance.\n",
      "   - **Published**: June 6, 2025  \n",
      "   - [Read more](http://arxiv.org/abs/2506.05690v1)\n",
      "\n",
      "2. **A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models**  \n",
      "   - **Abstract**: This survey analyzes Graph-based Retrieval-Augmented Generation (GraphRAG) and its innovations to improve domain-specific LLM applications.\n",
      "   - **Published**: January 21, 2025  \n",
      "   - [Read more](http://arxiv.org/abs/2501.13958v2)\n",
      "\n",
      "3. **GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation**  \n",
      "   - **Abstract**: The paper introduces GraphRAG-Bench, a benchmark designed to evaluate GraphRAG models with a focus on complex reasoning tasks.\n",
      "   - **Published**: June 3, 2025  \n",
      "   - [Read more](http://arxiv.org/abs/2506.02404v3)\n",
      "\n",
      "4. **Beyond Single Pass, Looping Through Time: KG-IRAG with Iterative Knowledge Retrieval**  \n",
      "   - **Abstract**: This work presents a framework that integrates Knowledge Graphs with iterative reasoning to enhance LLMs' performance on complex queries.\n",
      "   - **Published**: March 18, 2025  \n",
      "   - [Read more](http://arxiv.org/abs/2503.14234v3)\n",
      "\n",
      "5. **How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG**  \n",
      "   - **Abstract**: The paper proposes an unbiased evaluation framework for GraphRAG methods, addressing flaws in current evaluation practices.\n",
      "   - **Published**: May 31, 2025  \n",
      "   - [Read more](http://arxiv.org/abs/2506.06331v1)\n",
      "\n",
      "These papers focus on advancements in graph-based retrieval and reasoning in the context of large language models.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(run_agent(\"show me papers by Xiao Huang\", irispy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aaaadeb4-2cdb-4d88-9141-757c93bee537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] step 1\n",
      "[Agent] → get_papers_by_topic({'topic': 'Knowledge Graphs'})\n",
      "[Agent] result: [{\"doc_id\": 1, \"paper\": \"Benchmarking Vector, Graph And Hybrid Retrieval Augmented Generation (Rag) Pipelines For Open Radio Access Networks (Oran)\", \"topic\": \"Knowledge Graphs\", \"relation\": \"COVERS\",...\n",
      "\n",
      "[Agent] step 2\n",
      "[Agent] ✓ Final answer\n",
      "Here are some recent papers related to Knowledge Graphs:\n",
      "\n",
      "1. **Benchmarking Vector, Graph and Hybrid Retrieval Augmented Generation (RAG) Pipelines for Open Radio Access Networks (ORAN)**  \n",
      "   - **Authors**: Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Syed Ali Raza Zaidi  \n",
      "   - **Published**: 2025-07-04  \n",
      "   - **Abstract**: This paper evaluates various RAG systems, including GraphRAG, in the context of ORAN, highlighting their performance in multi-hop reasoning.  \n",
      "   - [Read more](http://arxiv.org/abs/2507.03608v2)\n",
      "\n",
      "2. **RAG vs. GraphRAG: A Systematic Evaluation and Key Insights**  \n",
      "   - **Authors**: Haoyu Han, Harry Shomer, et al.  \n",
      "   - **Published**: 2025-02-17  \n",
      "   - **Abstract**: A systematic evaluation comparing RAG and GraphRAG on benchmark tasks, discussing their strengths and integration strategies.  \n",
      "   - [Read more](http://arxiv.org/abs/2502.11371v1)\n",
      "\n",
      "3. **Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs**  \n",
      "   - **Authors**: Travis Thompson, SeungHwan Lim, et al.  \n",
      "   - **Published**: 2025-06-24  \n",
      "   - **Abstract**: Introduces a framework that enhances multi-hop question answering performance using inference-time compute scaling.  \n",
      "   - [Read more](http://arxiv.org/abs/2506.19967v1)\n",
      "\n",
      "4. **T-GRAG: A Dynamic GraphRAG Framework for Resolving Temporal Conflicts and Redundancy in Knowledge Retrieval**  \n",
      "   - **Authors**: Dong Li, Yichen Niu, et al.  \n",
      "   - **Published**: 2025-08-03  \n",
      "   - **Abstract**: Proposes a dynamic framework that models the evolution of knowledge over time to improve retrieval accuracy.  \n",
      "   - [Read more](http://arxiv.org/abs/2508.01680v1)\n",
      "\n",
      "5. **Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems**  \n",
      "   - **Authors**: Ziqi Zhu, Tao Hu, et al.  \n",
      "   - **Published**: 2025-06-24  \n",
      "   - **Abstract**: Introduces a framework that improves dialogue systems by integrating intent transition graphs with semantic search.  \n",
      "   - [Read more](http://arxiv.org/abs/2506.19385v1)\n",
      "\n",
      "These papers explore various aspects of Knowledge Graphs, including their application in retrieval-augmented generation, multi-hop reasoning, and dialogue systems.\n"
     ]
    }
   ],
   "source": [
    "print(run_agent(\"papers about Knowledge Graphs\", irispy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1f00b6-1510-45e5-8d90-cc2ca297abff",
   "metadata": {},
   "source": [
    "## LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "427c8d91-0b8d-4793-bde1-de95245983b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_query_llm(user_query: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": (\n",
    "            \"Classify the user's question as exactly one word: \"\n",
    "            \"'aggregation' (asks for counts, most/least, top, number of) \"\n",
    "            \"or 'general' (everything else). Reply with only that word.\"\n",
    "        )},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "    resp = send_to_llm(model, messages)  # uses your wrapper\n",
    "    label = (resp.choices[0].message.content or \"\").strip().lower()\n",
    "    return \"aggregation\" if \"aggregation\" in label else \"general\"\n",
    "\n",
    "def ask_question_graphrag_agent(user_query: str,\n",
    "                 irispy,\n",
    "                 combined_results,\n",
    "                 search_query: str | None = None,\n",
    "                 debug: bool = True):\n",
    "    \n",
    "    qtype = classify_query_llm(user_query)\n",
    "    if debug:\n",
    "        print(f\"[Router] classified as: {qtype}\")\n",
    "\n",
    "    if qtype == \"aggregation\":\n",
    "        return run_agent(user_query, irispy, debug=debug)\n",
    "    else:\n",
    "        q_for_rag = search_query or user_query\n",
    "        return ask_question_graphrag( q_for_rag, engine, emb_model, irispy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "be609092-f672-4042-b1ce-38c0669e6660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Router] classified as: aggregation\n",
      "[Agent] step 1\n",
      "[Agent] → get_top_authors_by_paper_count({'limit': 5})\n",
      "[Agent] result: [{\"author\": \"Xiao Huang\", \"count\": 5, \"papers\": [{\"doc_id\": 0, \"paper_node\": \"When To Use Graphs In Rag: A Comprehensive Analysis For Graph Retrieval-Augmented Generation\", \"title\": \"When to use Graph...\n",
      "\n",
      "[Agent] step 2\n",
      "[Agent] ✓ Final answer\n",
      "The author who has written the most papers about Knowledge Graphs is **Xiao Huang**, with a total of **5 papers**. Here are some of the notable papers authored by him:\n",
      "\n",
      "1. **[When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation](http://arxiv.org/abs/2506.05690v1)** - This paper discusses the effectiveness of Graph Retrieval-Augmented Generation (GraphRAG) in enhancing large language models with external knowledge.\n",
      "   \n",
      "2. **[A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models](http://arxiv.org/abs/2501.13958v2)** - This survey analyzes the challenges and innovations in GraphRAG for customizing large language models.\n",
      "\n",
      "3. **[GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation](http://arxiv.org/abs/2506.02404v3)** - This paper introduces a benchmark for evaluating GraphRAG models, focusing on domain-specific reasoning.\n",
      "\n",
      "4. **[Beyond Single Pass, Looping Through Time: KG-IRAG with Iterative Knowledge Retrieval](http://arxiv.org/abs/2503.14234v3)** - This work presents a framework that integrates knowledge graphs with iterative reasoning for improved performance in complex tasks.\n",
      "\n",
      "5. **[How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG](http://arxiv.org/abs/2506.06331v1)** - This paper proposes an unbiased evaluation framework for assessing the performance of GraphRAG methods.\n",
      "\n",
      "Other notable authors in the field include Chuang Zhou, Haoyu Han, Harry Shomer, and Jiliang Tang, each with 3 papers related to Knowledge Graphs.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who has written the most papers about Knowledge Graphs?\"\n",
    "combined_results = prepare_combined_results(query, engine, emb_model, irispy)\n",
    "print(ask_question_graphrag_agent(query, irispy, combined_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "90cb4eeb-e4e9-44ca-9555-154b6bc47986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Router] classified as: general\n",
      "The paper titled \"From Local to Global: A Graph RAG Approach to Query-Focused Summarization\" covers the most topics, with a total of 25 distinct topics mentioned in its graph context. This includes areas such as Retrieval-Augmented Generation, Knowledge Graphs, and various aspects of large language models. Its comprehensive approach to query-focused summarization highlights its broad scope in the field.\n",
      "[Router] classified as: general\n",
      "[Router] classified as: general\n",
      "[Router] classified as: aggregation\n",
      "[Agent] step 1\n",
      "[Agent] → get_top_authors_by_paper_count({'limit': 5})\n",
      "[Agent] result: [{\"author\": \"Xiao Huang\", \"count\": 5, \"papers\": [{\"doc_id\": 0, \"paper_node\": \"When To Use Graphs In Rag: A Comprehensive Analysis For Graph Retrieval-Augmented Generation\", \"title\": \"When to use Graph...\n",
      "\n",
      "[Agent] step 2\n",
      "[Agent] ✓ Final answer\n"
     ]
    }
   ],
   "source": [
    "query = \"which paper covers most topics?\"\n",
    "combined_results = prepare_combined_results(query, engine, emb_model, irispy)\n",
    "print(ask_question_graphrag_agent(query, irispy, combined_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e3f48857-94d9-476b-a460-169d4eb405f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Router] classified as: general\n",
      "['Several authors have written papers about GraphRAG, including Yukun Cao, Zengyi Gao, and Zhiyang Li in \"LEGO-GraphRAG,\" and Boci Peng, Yun Zhu, and Yongchao Liu in \"Graph Retrieval-Augmented Generation: A Survey.\" Additionally, Haoyu Han, Harry Shomer, and Jiliang Tang contributed to \"Empowering GraphRAG with Knowledge Filtering and Integration.\" Other authors include Shiqi Zhang, Xiaokui Xiao, and Yiqian Huang in \"Ket-Rag: A Cost-Efficient Multi-Granular Indexing Framework For Graph-Rag.\"']\n"
     ]
    }
   ],
   "source": [
    "query = \"who has written paper about graphrag?\"\n",
    "combined_results = prepare_combined_results(query, engine, emb_model, irispy)\n",
    "print(ask_question_graphrag_agent(query, irispy, combined_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "979ff279-0b4f-4bdb-9303-001cc93b59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Router] classified as: aggregation\n",
      "[Agent] step 1\n",
      "[Agent] → get_papers_by_author({'author': 'Fan Ji'})\n",
      "[Agent] result: []...\n",
      "\n",
      "[Agent] step 2\n",
      "[Agent] ✓ Final answer\n",
      "Fan Ji has not authored any papers.\n"
     ]
    }
   ],
   "source": [
    "query = \"how many peper has Fan Ji written?\"\n",
    "combined_results = prepare_combined_results(query, engine, emb_model, irispy)\n",
    "print(ask_question_graphrag_agent(query, irispy, combined_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1b5c7e4c-fa21-4bd0-b983-78bfe5068041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/q0pvzbmx0y793pp4gl7pm25sffw2vg/T/ipykernel_3954/3753658931.py:105: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  rag_chat = gr.Chatbot(label=\"\", height=420)\n",
      "/var/folders/vl/q0pvzbmx0y793pp4gl7pm25sffw2vg/T/ipykernel_3954/3753658931.py:108: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  graphrag_chat = gr.Chatbot(label=\"\", height=420)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def compare_handler(query: str, rag_hist, graphrag_hist):\n",
    "    if not query.strip():\n",
    "        return rag_hist, graphrag_hist, \"⚠️ Please enter a question.\"\n",
    "\n",
    "    # RAG\n",
    "    try:\n",
    "        rag_answer = ask_question_rag(query, engine, emb_model)\n",
    "    except Exception as e:\n",
    "        rag_answer = f\"RAG error: {e}\"\n",
    "\n",
    "    # GraphRAG Agent\n",
    "    try:\n",
    "        graphrag_answer = ask_question_graphrag_agent(query, irispy, combined_results)\n",
    "    except Exception as e:\n",
    "        graphrag_answer = f\"GraphRAG error: {e}\"\n",
    "\n",
    "    rag_hist = list(rag_hist) + [(query, str(rag_answer))]\n",
    "    graphrag_hist = list(graphrag_hist) + [(query, str(graphrag_answer))]\n",
    "    return rag_hist, graphrag_hist, \"\"\n",
    "\n",
    "def clear_histories():\n",
    "    return [], [], \"\"\n",
    "\n",
    "\n",
    "\n",
    "custom_css = \"\"\"\n",
    ":root{\n",
    "  --brand-blue:  #2f3ea8;   /* navy blue */\n",
    "  --brand-teal:  #00a6a6;   /* teal */\n",
    "  --bg:          #f7f9fc;\n",
    "  --panel:       #ffffff;\n",
    "  --text:        #0f172a;\n",
    "  --shadow:      0 6px 16px rgba(17, 24, 39, .08);\n",
    "}\n",
    "\n",
    ".gradio-container { background: var(--bg); color: var(--text); }\n",
    "#title { text-align:center; font-size:24px; font-weight:700; margin: 12px 0 18px; color: var(--brand-blue); }\n",
    ".panel-title { font-weight:700; margin: 6px 0 10px; color: var(--brand-blue); }\n",
    "\n",
    ".gr-chatbot {\n",
    "  background: var(--panel) !important;\n",
    "  border-radius: 14px !important;\n",
    "  box-shadow: var(--shadow) !important;\n",
    "  padding: 8px !important;\n",
    "  border: 1px solid rgba(47,62,168,.10) !important;\n",
    "}\n",
    "\n",
    ".gr-chatbot .message,\n",
    ".gr-chatbot .message.user,\n",
    ".gr-chatbot .message.bot{\n",
    "  background: #fff !important;\n",
    "  color: var(--text) !important;\n",
    "  border-radius: 14px !important;\n",
    "  padding: 10px 14px !important;\n",
    "  box-shadow: 0 2px 6px rgba(0,0,0,.04);\n",
    "  border-left: 4px solid var(--brand-teal);\n",
    "  font-size: 16px !important;\n",
    "}\n",
    "\n",
    "/* inputs */\n",
    "textarea, input, .gr-textbox, .gr-textbox textarea{\n",
    "  border-radius: 12px !important;\n",
    "  border: 1px solid rgba(47,62,168,.18) !important;\n",
    "}\n",
    ".gr-textbox textarea:focus{ outline: none !important; border-color: var(--brand-blue) !important; }\n",
    "\n",
    "/* buttons */\n",
    ".gr-button{ border-radius: 12px !important; font-weight:600 !important; }\n",
    "button.primary, .gr-button-primary{\n",
    "  background: var(--brand-teal) !important;\n",
    "  border: none !important;\n",
    "  color: #fff !important;\n",
    "}\n",
    "button.secondary, .gr-button-secondary{\n",
    "  background: #fff !important;\n",
    "  color: var(--brand-blue) !important;\n",
    "  border: 1px solid rgba(47,62,168,.25) !important;\n",
    "}\n",
    "\n",
    "/* hide default Chatbot legend */\n",
    ".gr-chatbot .label, .gr-chatbot .legend, .gr-chatbot > div:first-child > div:first-child {\n",
    "  display: none !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with gr.Blocks(css=custom_css) as demo:\n",
    "    gr.HTML('<div id=\"title\">RAG vs GraphRAG</div>')\n",
    "\n",
    "    rag_state = gr.State([])\n",
    "    graphrag_state = gr.State([])\n",
    "\n",
    "    with gr.Row():\n",
    "        query_in = gr.Textbox(\n",
    "            label=\"Your question\",\n",
    "            placeholder=\"e.g., Who has written the most paper?\"\n",
    "        )\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown('<div class=\"panel-title\">RAG</div>')\n",
    "            rag_chat = gr.Chatbot(label=\"\", height=420)\n",
    "        with gr.Column():\n",
    "            gr.Markdown('<div class=\"panel-title\">GraphRAG</div>')\n",
    "            graphrag_chat = gr.Chatbot(label=\"\", height=420)\n",
    "\n",
    "    run_btn = gr.Button(\"Ask Both\", variant=\"primary\")\n",
    "    clear_btn = gr.Button(\"Clear\", variant=\"secondary\")\n",
    "    status_out = gr.Markdown(\"\")\n",
    "\n",
    "    run_btn.click(\n",
    "        fn=compare_handler,\n",
    "        inputs=[query_in, rag_state, graphrag_state],\n",
    "        outputs=[rag_chat, graphrag_chat, status_out]\n",
    "    ).then(\n",
    "        fn=lambda a,b: (a,b),\n",
    "        inputs=[rag_chat, graphrag_chat],\n",
    "        outputs=[rag_state, graphrag_state]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        fn=clear_histories,\n",
    "        inputs=[],\n",
    "        outputs=[rag_chat, graphrag_chat, status_out]\n",
    "    ).then(\n",
    "        fn=lambda: ([], []),\n",
    "        inputs=[],\n",
    "        outputs=[rag_state, graphrag_state]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aabc32ec-b632-4075-8ef4-1b6729b9318c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Router] classified as: aggregation\n",
      "[Agent] step 1\n",
      "[Agent] → get_papers_by_author({'author': 'Fan Ji'})\n",
      "[Agent] result: []...\n",
      "\n",
      "[Agent] step 2\n",
      "[Agent] ✓ Final answer\n",
      "[Router] classified as: general\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e0a85-7f43-4beb-8701-04ebab3d1068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
